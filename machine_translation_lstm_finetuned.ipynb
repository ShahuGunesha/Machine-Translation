{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 10862870,
          "sourceType": "datasetVersion",
          "datasetId": 6748299
        },
        {
          "sourceId": 10862930,
          "sourceType": "datasetVersion",
          "datasetId": 6748347
        }
      ],
      "dockerImageVersionId": 31040,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "machine-translation-lstm-finetuned",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:51.891396Z",
          "iopub.execute_input": "2025-06-18T07:21:51.891654Z",
          "iopub.status.idle": "2025-06-18T07:21:51.916658Z",
          "shell.execute_reply.started": "2025-06-18T07:21:51.891625Z",
          "shell.execute_reply": "2025-06-18T07:21:51.915711Z"
        },
        "id": "KY7ULJGgujDu",
        "outputId": "8e5c78ab-04d8-485e-e4f5-7feeb344d373"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/trainnn/train_data1.json\n/kaggle/input/validation/val_data1.json\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:51.917629Z",
          "iopub.execute_input": "2025-06-18T07:21:51.917938Z",
          "iopub.status.idle": "2025-06-18T07:21:51.924505Z",
          "shell.execute_reply.started": "2025-06-18T07:21:51.917916Z",
          "shell.execute_reply": "2025-06-18T07:21:51.923605Z"
        },
        "id": "ka3kyYIgujDv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/kaggle/input/trainnn/train_data1.json', 'r') as file: # Replace this path with the dataset path in your local machine\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:51.925515Z",
          "iopub.execute_input": "2025-06-18T07:21:51.926229Z",
          "iopub.status.idle": "2025-06-18T07:21:52.830713Z",
          "shell.execute_reply.started": "2025-06-18T07:21:51.926199Z",
          "shell.execute_reply": "2025-06-18T07:21:52.829962Z"
        },
        "id": "OYT04WZqujDv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:52.831493Z",
          "iopub.execute_input": "2025-06-18T07:21:52.831866Z",
          "iopub.status.idle": "2025-06-18T07:21:52.837939Z",
          "shell.execute_reply.started": "2025-06-18T07:21:52.83184Z",
          "shell.execute_reply": "2025-06-18T07:21:52.837063Z"
        },
        "id": "nyrkP2UMujDw",
        "outputId": "4c516170-c1b2-43b9-997f-824bc94c04d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n",
          "output_type": "stream"
        },
        {
          "execution_count": 122,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Process JSON data\n",
        "source_sentences_train = []\n",
        "target_sentences_train = []\n",
        "\n",
        "source_sentences_val = []\n",
        "target_sentences_val = []\n",
        "\n",
        "id_train = []\n",
        "id_val = []"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:52.838809Z",
          "iopub.execute_input": "2025-06-18T07:21:52.839106Z",
          "iopub.status.idle": "2025-06-18T07:21:52.857246Z",
          "shell.execute_reply.started": "2025-06-18T07:21:52.83908Z",
          "shell.execute_reply": "2025-06-18T07:21:52.856338Z"
        },
        "id": "zRHBNi1WujDw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for language_pair, language_data in data.items():\n",
        "  print(f\"Language Pair: {language_pair}\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:52.858246Z",
          "iopub.execute_input": "2025-06-18T07:21:52.858567Z",
          "iopub.status.idle": "2025-06-18T07:21:52.87618Z",
          "shell.execute_reply.started": "2025-06-18T07:21:52.858541Z",
          "shell.execute_reply": "2025-06-18T07:21:52.87511Z"
        },
        "id": "GMaofRHWujDx",
        "outputId": "a83a31af-3109-4d2c-836d-46f72286e271"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Language Pair: English-Bengali\nLanguage Pair: English-Hindi\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for language_pair, language_data in data.items():\n",
        "    if(language_pair == \"English-Hindi\"):\n",
        "      print(f\"Language Pair: {language_pair}\")\n",
        "      for data_type, data_entries in language_data.items():\n",
        "          print(f\"  Data Type: {data_type}\")\n",
        "          for entry_id, entry_data in data_entries.items():\n",
        "              source = entry_data[\"source\"]\n",
        "              target = entry_data[\"target\"]\n",
        "              if (data_type == \"Validation\"):\n",
        "                source_sentences_val.append(source)\n",
        "                target_sentences_val.append(target)\n",
        "                id_val.append(entry_id)\n",
        "              else:\n",
        "                source_sentences_train.append(source)\n",
        "                target_sentences_train.append(target)\n",
        "                id_train.append(entry_id)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:52.87742Z",
          "iopub.execute_input": "2025-06-18T07:21:52.877742Z",
          "iopub.status.idle": "2025-06-18T07:21:52.946939Z",
          "shell.execute_reply.started": "2025-06-18T07:21:52.877714Z",
          "shell.execute_reply": "2025-06-18T07:21:52.946085Z"
        },
        "id": "9ZoLs7b2ujDx",
        "outputId": "7676eca7-0804-4010-e099-b773201eaf2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Language Pair: English-Hindi\n  Data Type: Train\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/kaggle/input/validation/val_data1.json', 'r') as file: # Replace this path with the dataset path in your local machine\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:52.947803Z",
          "iopub.execute_input": "2025-06-18T07:21:52.9481Z",
          "iopub.status.idle": "2025-06-18T07:21:53.029329Z",
          "shell.execute_reply.started": "2025-06-18T07:21:52.948073Z",
          "shell.execute_reply": "2025-06-18T07:21:53.028347Z"
        },
        "id": "Pa8ZHIexujDy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for language_pair, language_data in data.items():\n",
        "    if(language_pair == \"English-Hindi\"):\n",
        "      print(f\"Language Pair: {language_pair}\")\n",
        "      for data_type, data_entries in language_data.items():\n",
        "          print(f\"  Data Type: {data_type}\")\n",
        "          for entry_id, entry_data in data_entries.items():\n",
        "              source = entry_data[\"source\"]\n",
        "              #target = entry_data[\"target\"]\n",
        "              if (data_type == \"Validation\"):\n",
        "                source_sentences_val.append(source)\n",
        "                #target_sentences_val.append(target)\n",
        "                #id_val.append(entry_id)\n",
        "              #else:\n",
        "                #source_sentences_train.append(source)\n",
        "                #target_sentences_train.append(target)\n",
        "                #id_train.append(entry_id)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:53.033494Z",
          "iopub.execute_input": "2025-06-18T07:21:53.03416Z",
          "iopub.status.idle": "2025-06-18T07:21:53.056689Z",
          "shell.execute_reply.started": "2025-06-18T07:21:53.034124Z",
          "shell.execute_reply": "2025-06-18T07:21:53.055093Z"
        },
        "id": "OacwGy_5ujDy",
        "outputId": "59ab107d-63de-46e7-cb22-3a18dbc92b69"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Language Pair: English-Hindi\n  Data Type: Validation\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(source_sentences_train))\n",
        "print(len(target_sentences_train))\n",
        "\n",
        "print(len(source_sentences_val))\n",
        "print(len(target_sentences_val))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:53.057796Z",
          "iopub.execute_input": "2025-06-18T07:21:53.058114Z",
          "iopub.status.idle": "2025-06-18T07:21:53.076407Z",
          "shell.execute_reply.started": "2025-06-18T07:21:53.058086Z",
          "shell.execute_reply": "2025-06-18T07:21:53.075335Z"
        },
        "id": "GxmsSchGujDz",
        "outputId": "dfe2ccb0-61d7-4d81-db0f-e8ac53a83575"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "80797\n80797\n11543\n0\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "x={'English':source_sentences_train,'Hindi':target_sentences_train}\n",
        "df=pd.DataFrame(x)\n",
        "df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:53.077434Z",
          "iopub.execute_input": "2025-06-18T07:21:53.077836Z",
          "iopub.status.idle": "2025-06-18T07:21:53.162089Z",
          "shell.execute_reply.started": "2025-06-18T07:21:53.077809Z",
          "shell.execute_reply": "2025-06-18T07:21:53.161338Z"
        },
        "id": "-vZCKkAsujDz",
        "outputId": "b02fda61-7165-4758-e40a-d978a1883c3b"
      },
      "outputs": [
        {
          "execution_count": 129,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                 English  \\\n0                       cancel everything on my calendar   \n1      Adrenal hormone levels are at their peak durin...   \n2      Golden threads are obtained from Surat, the qu...   \n3              Look for agglutination within 30 seconds.   \n4      The non-pompousness and informality of their l...   \n...                                                  ...   \n80792  So, is it that this is the optimization proble...   \n80793  In this Masjid made with red stones there are ...   \n80794  He began to work on the movie on August 17, 20...   \n80795                          start a new shopping list   \n80796                 turn off the lights in the kitchen   \n\n                                                   Hindi  \n0                       मेरे कैलेंडर पर सब कुछ रद्द करें  \n1      अधिवृक्क के हार्मोन का स्तर प्रातःकाल में अपने...  \n2      स्वर्ण धागे सूरत से प्राप्त होते हैं, जिनकी गु...  \n3                  30 सेकेण्ड के भीतर एग्लूटिनेशन देखें।  \n4      उनके जीवन की आडंबरहीनता एवं अनौपचारिकता उनके स...  \n...                                                  ...  \n80792   तो, यह अनुकूलन समस्या है जिसमें हम रुचि रखते थे।  \n80793  लाल पत्थरों से बनायी गयी इस मस्जिद में हिन्दू ...  \n80794  उन्होंने 17 अगस्त, 2010 को फिल्म पर काम करना श...  \n80795                       एक नई खरीदारी सूची शुरू करें  \n80796                        रसोईघर की बत्तियाँ बंद करें  \n\n[80797 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>Hindi</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>cancel everything on my calendar</td>\n      <td>मेरे कैलेंडर पर सब कुछ रद्द करें</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Adrenal hormone levels are at their peak durin...</td>\n      <td>अधिवृक्क के हार्मोन का स्तर प्रातःकाल में अपने...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Golden threads are obtained from Surat, the qu...</td>\n      <td>स्वर्ण धागे सूरत से प्राप्त होते हैं, जिनकी गु...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Look for agglutination within 30 seconds.</td>\n      <td>30 सेकेण्ड के भीतर एग्लूटिनेशन देखें।</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>The non-pompousness and informality of their l...</td>\n      <td>उनके जीवन की आडंबरहीनता एवं अनौपचारिकता उनके स...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>80792</th>\n      <td>So, is it that this is the optimization proble...</td>\n      <td>तो, यह अनुकूलन समस्या है जिसमें हम रुचि रखते थे।</td>\n    </tr>\n    <tr>\n      <th>80793</th>\n      <td>In this Masjid made with red stones there are ...</td>\n      <td>लाल पत्थरों से बनायी गयी इस मस्जिद में हिन्दू ...</td>\n    </tr>\n    <tr>\n      <th>80794</th>\n      <td>He began to work on the movie on August 17, 20...</td>\n      <td>उन्होंने 17 अगस्त, 2010 को फिल्म पर काम करना श...</td>\n    </tr>\n    <tr>\n      <th>80795</th>\n      <td>start a new shopping list</td>\n      <td>एक नई खरीदारी सूची शुरू करें</td>\n    </tr>\n    <tr>\n      <th>80796</th>\n      <td>turn off the lights in the kitchen</td>\n      <td>रसोईघर की बत्तियाँ बंद करें</td>\n    </tr>\n  </tbody>\n</table>\n<p>80797 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from collections import Counter"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:53.162762Z",
          "iopub.execute_input": "2025-06-18T07:21:53.163021Z",
          "iopub.status.idle": "2025-06-18T07:21:53.169803Z",
          "shell.execute_reply.started": "2025-06-18T07:21:53.162999Z",
          "shell.execute_reply": "2025-06-18T07:21:53.166339Z"
        },
        "id": "_nPF08YpujDz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to preprocess and remove punctuation and numbers\n",
        "def preprocess_and_remove_punctuation(sentence):\n",
        "    # Remove punctuation and numbers\n",
        "    sentence = ''.join([char for char in sentence if char not in string.punctuation and not char.isdigit()])\n",
        "    return sentence\n",
        "\n",
        "# Tokenization and Lowercasing\n",
        "def preprocess(sentences):\n",
        "    tokenized_sentences = [nltk.word_tokenize(preprocess_and_remove_punctuation(sentence.lower())) for sentence in sentences]\n",
        "    return tokenized_sentences"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:53.171227Z",
          "iopub.execute_input": "2025-06-18T07:21:53.171539Z",
          "iopub.status.idle": "2025-06-18T07:21:53.194648Z",
          "shell.execute_reply.started": "2025-06-18T07:21:53.171512Z",
          "shell.execute_reply": "2025-06-18T07:21:53.193403Z"
        },
        "id": "mbel2TjIujDz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "target_sentences_train = [re.sub(r'[a-zA-Z]','',hi) for hi in target_sentences_train]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:53.195669Z",
          "iopub.execute_input": "2025-06-18T07:21:53.196344Z",
          "iopub.status.idle": "2025-06-18T07:21:53.409158Z",
          "shell.execute_reply.started": "2025-06-18T07:21:53.196311Z",
          "shell.execute_reply": "2025-06-18T07:21:53.408262Z"
        },
        "id": "qOfYTUweujDz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "english_tokens = preprocess(source_sentences_train)\n",
        "english_test=preprocess(source_sentences_val)\n",
        "hindi_tokens = preprocess(target_sentences_train)\n",
        "hindi_test=preprocess(target_sentences_val)\n",
        "\n",
        "en_train=english_tokens\n",
        "en_test=english_test\n",
        "de_train=hindi_tokens\n",
        "de_test=hindi_test"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:21:53.409979Z",
          "iopub.execute_input": "2025-06-18T07:21:53.410254Z",
          "iopub.status.idle": "2025-06-18T07:22:12.870667Z",
          "shell.execute_reply.started": "2025-06-18T07:21:53.410234Z",
          "shell.execute_reply": "2025-06-18T07:22:12.869761Z"
        },
        "id": "BnRGpHSNujD0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "en_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
        "de_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
        "\n",
        "for ds in [en_train, en_test]:\n",
        "    for sent in ds:\n",
        "        for token in sent:\n",
        "            if token not in en_index2word:\n",
        "                en_index2word.append(token)\n",
        "\n",
        "for ds in [de_train, de_test]:\n",
        "    for sent in ds:\n",
        "        for token in sent:\n",
        "            if token not in de_index2word:\n",
        "                de_index2word.append(token)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:22:12.871865Z",
          "iopub.execute_input": "2025-06-18T07:22:12.872845Z",
          "iopub.status.idle": "2025-06-18T07:28:04.243478Z",
          "shell.execute_reply.started": "2025-06-18T07:22:12.872818Z",
          "shell.execute_reply": "2025-06-18T07:28:04.242535Z"
        },
        "id": "Bl_mh9zyujD0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(en_index2word[:5])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:04.244373Z",
          "iopub.execute_input": "2025-06-18T07:28:04.244591Z",
          "iopub.status.idle": "2025-06-18T07:28:04.249735Z",
          "shell.execute_reply.started": "2025-06-18T07:28:04.244567Z",
          "shell.execute_reply": "2025-06-18T07:28:04.248779Z"
        },
        "id": "oR72c2XQujD0",
        "outputId": "b0fd87d3-c903-4b58-8448-308b59b90327"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "['<PAD>', '<SOS>', '<EOS>', 'cancel', 'everything']\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:04.250787Z",
          "iopub.execute_input": "2025-06-18T07:28:04.251078Z",
          "iopub.status.idle": "2025-06-18T07:28:04.270057Z",
          "shell.execute_reply.started": "2025-06-18T07:28:04.251047Z",
          "shell.execute_reply": "2025-06-18T07:28:04.269165Z"
        },
        "id": "13IUunL9ujD0",
        "outputId": "2607bc5b-6b20-4734-f2a0-8986bda809b2"
      },
      "outputs": [
        {
          "execution_count": 136,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cpu')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "en_word2index = {token: idx for idx, token in enumerate(en_index2word)}\n",
        "de_word2index = {token: idx for idx, token in enumerate(de_index2word)}\n",
        "\n",
        "len(en_word2index)\n",
        "\n",
        "\n",
        "en_lengths = sum([len(sent) for sent in en_train])/len(en_train)\n",
        "de_lengths = sum([len(sent) for sent in de_train])/len(de_train)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:04.270976Z",
          "iopub.execute_input": "2025-06-18T07:28:04.271265Z",
          "iopub.status.idle": "2025-06-18T07:28:04.383113Z",
          "shell.execute_reply.started": "2025-06-18T07:28:04.271246Z",
          "shell.execute_reply": "2025-06-18T07:28:04.382306Z"
        },
        "id": "ocI_uooDujD0"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 25\n",
        "\n",
        "def encode_and_pad(vocab, sent, max_length):\n",
        "    sos = [vocab[\"<SOS>\"]]\n",
        "    eos = [vocab[\"<EOS>\"]]\n",
        "    pad = [vocab[\"<PAD>\"]]\n",
        "\n",
        "    if len(sent) < max_length - 2: # -2 for SOS and EOS\n",
        "        n_pads = max_length - 2 - len(sent)\n",
        "        encoded = [vocab[w] for w in sent]\n",
        "        return sos + encoded + eos + pad * n_pads\n",
        "    else: # sent is longer than max_length; truncating\n",
        "        encoded = [vocab[w] for w in sent]\n",
        "        truncated = encoded[:max_length - 2]\n",
        "        return sos + truncated + eos"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:04.384015Z",
          "iopub.execute_input": "2025-06-18T07:28:04.384264Z",
          "iopub.status.idle": "2025-06-18T07:28:04.390801Z",
          "shell.execute_reply.started": "2025-06-18T07:28:04.384245Z",
          "shell.execute_reply": "2025-06-18T07:28:04.389796Z"
        },
        "id": "AJAGrLzbujD1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "en_train_encoded = [encode_and_pad(en_word2index, sent, seq_length) for sent in en_train]\n",
        "en_test_encoded = [encode_and_pad(en_word2index, sent, seq_length) for sent in en_test]\n",
        "de_train_encoded = [encode_and_pad(de_word2index, sent, seq_length) for sent in de_train]\n",
        "de_test_encoded = [encode_and_pad(de_word2index, sent, seq_length) for sent in de_test]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:04.391932Z",
          "iopub.execute_input": "2025-06-18T07:28:04.392339Z",
          "iopub.status.idle": "2025-06-18T07:28:05.77726Z",
          "shell.execute_reply.started": "2025-06-18T07:28:04.392314Z",
          "shell.execute_reply": "2025-06-18T07:28:05.776413Z"
        },
        "id": "uMrIf4NaujD1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "en_train_encoded[1]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:05.778592Z",
          "iopub.execute_input": "2025-06-18T07:28:05.778857Z",
          "iopub.status.idle": "2025-06-18T07:28:05.78424Z",
          "shell.execute_reply.started": "2025-06-18T07:28:05.778838Z",
          "shell.execute_reply": "2025-06-18T07:28:05.783351Z"
        },
        "id": "xXjuc8j4ujD1",
        "outputId": "60371943-be5f-443c-be37-213def48275d"
      },
      "outputs": [
        {
          "execution_count": 140,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[1,\n 8,\n 9,\n 10,\n 11,\n 12,\n 13,\n 14,\n 15,\n 16,\n 17,\n 18,\n 19,\n 20,\n 15,\n 16,\n 21,\n 22,\n 23,\n 24,\n 25,\n 26,\n 27,\n 28,\n 2]"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "\n",
        "train_x = np.array(en_train_encoded)\n",
        "train_y = np.array(de_train_encoded)\n",
        "test_x = np.array(en_test_encoded)\n",
        "test_y = np.array(de_test_encoded)\n",
        "\n",
        "train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "test_ds = TensorDataset(torch.from_numpy(test_x))\n",
        "\n",
        "\n",
        "train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "#test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size, drop_last=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:05.785486Z",
          "iopub.execute_input": "2025-06-18T07:28:05.785781Z",
          "iopub.status.idle": "2025-06-18T07:28:06.216442Z",
          "shell.execute_reply.started": "2025-06-18T07:28:05.785756Z",
          "shell.execute_reply": "2025-06-18T07:28:06.215619Z"
        },
        "id": "KmvRWRzeujD1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_x[1]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.217246Z",
          "iopub.execute_input": "2025-06-18T07:28:06.21748Z",
          "iopub.status.idle": "2025-06-18T07:28:06.223619Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.217464Z",
          "shell.execute_reply": "2025-06-18T07:28:06.222657Z"
        },
        "id": "v58ftwIBujD1",
        "outputId": "6efb3fbe-3728-40ff-c48b-81f37c15d2bb"
      },
      "outputs": [
        {
          "execution_count": 142,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([ 1,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 15, 16, 21,\n       22, 23, 24, 25, 26, 27, 28,  2])"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[1]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.224577Z",
          "iopub.execute_input": "2025-06-18T07:28:06.225082Z",
          "iopub.status.idle": "2025-06-18T07:28:06.242485Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.225059Z",
          "shell.execute_reply": "2025-06-18T07:28:06.241659Z"
        },
        "id": "4XrhiR9lujD1",
        "outputId": "b3046880-7661-4972-b83f-794b848ebc4f"
      },
      "outputs": [
        {
          "execution_count": 143,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(tensor([ 1,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 15, 16, 21, 22,\n         23, 24, 25, 26, 27, 28,  2]),\n tensor([ 1, 10, 11, 12, 13, 14, 15, 16, 17, 18,  5, 19, 20, 21, 22, 23, 24, 25,\n         26, 14,  5, 27, 28, 29,  2]))"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=0)\n",
        "\n",
        "        # Bidirectional GRU\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "        self.num_directions = 2 if self.lstm.bidirectional else 1\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input)\n",
        "        output, hidden = self.lstm(embedded, hidden)\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self, batch_size):\n",
        "        h0 = torch.zeros(self.num_directions, batch_size, self.hidden_size)\n",
        "        c0 = torch.zeros(self.num_directions, batch_size, self.hidden_size)\n",
        "        return h0.to(device), c0.to(device)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.243434Z",
          "iopub.execute_input": "2025-06-18T07:28:06.243643Z",
          "iopub.status.idle": "2025-06-18T07:28:06.257512Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.243626Z",
          "shell.execute_reply": "2025-06-18T07:28:06.25649Z"
        },
        "id": "SttRMNX8ujD2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input)                  # (batch, 1, hidden)\n",
        "        output = F.relu(embedded)\n",
        "        output, (hidden, cell) = self.lstm(output, hidden)\n",
        "        output = self.softmax(self.out(output.squeeze(1)))  # (batch, output_size)\n",
        "        return output, (hidden, cell)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.258508Z",
          "iopub.execute_input": "2025-06-18T07:28:06.258821Z",
          "iopub.status.idle": "2025-06-18T07:28:06.280699Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.258782Z",
          "shell.execute_reply": "2025-06-18T07:28:06.279749Z"
        },
        "id": "s-8Lv7HiujD2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "seq_length = 25\n",
        "\n",
        "encoder = EncoderRNN(len(en_index2word), hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, len(de_index2word)).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.281526Z",
          "iopub.execute_input": "2025-06-18T07:28:06.281825Z",
          "iopub.status.idle": "2025-06-18T07:28:06.561573Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.2818Z",
          "shell.execute_reply": "2025-06-18T07:28:06.560586Z"
        },
        "id": "oji1-K-pujD2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "encoder"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.562548Z",
          "iopub.execute_input": "2025-06-18T07:28:06.562871Z",
          "iopub.status.idle": "2025-06-18T07:28:06.569097Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.562842Z",
          "shell.execute_reply": "2025-06-18T07:28:06.568203Z"
        },
        "id": "OkhrNzXwujD2",
        "outputId": "91e2ed82-38db-41da-92a2-623e04f92244"
      },
      "outputs": [
        {
          "execution_count": 147,
          "output_type": "execute_result",
          "data": {
            "text/plain": "EncoderRNN(\n  (embedding): Embedding(61208, 128, padding_idx=0)\n  (lstm): LSTM(128, 128, batch_first=True, bidirectional=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "decoder"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.570057Z",
          "iopub.execute_input": "2025-06-18T07:28:06.570374Z",
          "iopub.status.idle": "2025-06-18T07:28:06.586218Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.570345Z",
          "shell.execute_reply": "2025-06-18T07:28:06.585347Z"
        },
        "id": "HyT2cfPtujD2",
        "outputId": "ea0ff605-9f01-4716-def9-16c9a0d7a775"
      },
      "outputs": [
        {
          "execution_count": 148,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DecoderRNN(\n  (embedding): Embedding(72202, 128)\n  (lstm): LSTM(128, 128, batch_first=True)\n  (out): Linear(in_features=128, out_features=72202, bias=True)\n  (softmax): LogSoftmax(dim=1)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "enc_optimizer = torch.optim.Adam(encoder.parameters(), lr = 3e-3)\n",
        "dec_optimizer = torch.optim.Adam(decoder.parameters(), lr = 3e-3)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.587455Z",
          "iopub.execute_input": "2025-06-18T07:28:06.587728Z",
          "iopub.status.idle": "2025-06-18T07:28:06.605301Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.587689Z",
          "shell.execute_reply": "2025-06-18T07:28:06.604169Z"
        },
        "id": "MmunQ3eNujD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "\n",
        "input_length = target_length = seq_length\n",
        "\n",
        "SOS = en_word2index[\"<SOS>\"]\n",
        "EOS = en_word2index[\"<EOS>\"]\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for idx, batch in enumerate(train_dl):\n",
        "\n",
        "        # Creating initial hidden states for the encoder\n",
        "        encoder_hidden = encoder.initHidden(batch_size)\n",
        "\n",
        "        # Sending to device\n",
        "        encoder_hidden = (encoder_hidden[0].to(device), encoder_hidden[1].to(device))\n",
        "\n",
        "\n",
        "        # Assigning the input and sending to device\n",
        "        input_tensor = batch[0].to(device)\n",
        "\n",
        "        # Assigning the output and sending to device\n",
        "        target_tensor = batch[1].to(device)\n",
        "\n",
        "\n",
        "        # Clearing gradients\n",
        "        enc_optimizer.zero_grad()\n",
        "        dec_optimizer.zero_grad()\n",
        "\n",
        "        # Enabling gradient calculation\n",
        "        with torch.set_grad_enabled(True):\n",
        "\n",
        "            # Feeding batch into encoder\n",
        "            encoder_output, (hidden, cell) = encoder(input_tensor, encoder_hidden)\n",
        "            encoder_hidden = (hidden, cell)\n",
        "\n",
        "            # This is a placeholder tensor for decoder outputs. We send it to device as well\n",
        "            dec_result = torch.zeros(target_length, batch_size, len(de_index2word)).to(device)\n",
        "\n",
        "            # Creating a batch of SOS tokens which will all be fed to the decoder\n",
        "            decoder_input = target_tensor[:, 0].unsqueeze(1).to(device)\n",
        "\n",
        "            decoder_hidden = (\n",
        "                hidden.mean(dim=0, keepdim=True),\n",
        "                cell.mean(dim=0, keepdim=True)\n",
        "            )\n",
        "\n",
        "            # For each time-step in decoding:\n",
        "            for i in range(1, target_length):\n",
        "\n",
        "                # Feed input and previous hidden states\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "\n",
        "                # Finding the best scoring word\n",
        "                best = decoder_output.argmax(1)\n",
        "\n",
        "                # Assigning next input as current best word\n",
        "                decoder_input = best.unsqueeze(1)\n",
        "\n",
        "                # Creating an entry in the placeholder output tensor\n",
        "                dec_result[i] = decoder_output\n",
        "\n",
        "\n",
        "            # Creating scores and targets for loss calculation\n",
        "            scores = dec_result.transpose(1, 0)[1:].reshape(-1, dec_result.shape[2])\n",
        "            targets = target_tensor[1:].reshape(-1)\n",
        "\n",
        "            # Calculating loss\n",
        "            loss = criterion(scores, targets)\n",
        "\n",
        "            # Performing backprop and clipping excess gradients\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n",
        "\n",
        "            enc_optimizer.step()\n",
        "            dec_optimizer.step()\n",
        "\n",
        "            # Keeping track of loss\n",
        "            losses.append(loss.item())\n",
        "            if idx % 100 == 0:\n",
        "                print(idx, sum(losses)/len(losses))\n",
        "\n",
        "plt.plot(losses)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T08:30:32.883967Z",
          "iopub.execute_input": "2025-06-18T08:30:32.884525Z",
          "iopub.status.idle": "2025-06-18T08:30:49.344764Z",
          "shell.execute_reply.started": "2025-06-18T08:30:32.884498Z",
          "shell.execute_reply": "2025-06-18T08:30:49.343555Z"
        },
        "id": "qixHpBGEujD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "val_ids = [ i for i,_ in data[\"English-Hindi\"][\"Validation\"].items()]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.912517Z",
          "iopub.status.idle": "2025-06-18T07:28:06.912828Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.912695Z",
          "shell.execute_reply": "2025-06-18T07:28:06.912706Z"
        },
        "id": "Z5tqVcuRujD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val_outs = []\n",
        "for i in tqdm(range(len(test_ds))):\n",
        "    # Fix 1: Initialize encoder hidden state with correct bidirectional dimensions\n",
        "    encoder_hidden = torch.zeros(2, 1, hidden_size).to(device)  # (2 directions, batch_size=1, hidden_size)\n",
        "\n",
        "    input_tensor = test_ds[i][0].unsqueeze(dim=0).to(device)\n",
        "    result = []\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        encoder_output, (hidden, cell) = encoder(input_tensor, encoder_hidden)\n",
        "        encoder_hidden = (hidden, cell)\n",
        "\n",
        "        # Fix 2: Prepare decoder hidden state by averaging bidirectional layers\n",
        "        decoder_hidden = hidden.mean(dim=0).unsqueeze(0)  # (1 layer, batch_size=1, hidden_size)\n",
        "\n",
        "        decoder_input = torch.tensor([SOS]).unsqueeze(dim=1).to(device)  # (batch=1, seq_len=1)\n",
        "\n",
        "        for di in range(1, target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            best = decoder_output.argmax(1)\n",
        "            result.append(de_index2word[best.to('cpu').item()])\n",
        "\n",
        "            if best.item() == EOS:\n",
        "                break\n",
        "\n",
        "            # Maintain consistent dimension for next input\n",
        "            decoder_input = best.unsqueeze(1)  # (batch=1, seq_len=1)\n",
        "\n",
        "    result = [i for i in result if i not in ['<EOS>', '<PAD>', '<SOS>']]\n",
        "    val_outs.append(\" \".join(result))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.913457Z",
          "iopub.status.idle": "2025-06-18T07:28:06.913928Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.913655Z",
          "shell.execute_reply": "2025-06-18T07:28:06.913672Z"
        },
        "id": "Y7gaxI-CujD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = pd.DataFrame()\n",
        "df0[\"ID\"] = val_ids\n",
        "df0[\"Translation\"] = val_outs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.914832Z",
          "iopub.status.idle": "2025-06-18T07:28:06.915152Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.915018Z",
          "shell.execute_reply": "2025-06-18T07:28:06.915036Z"
        },
        "id": "oxHwz8UIujD3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df0.to_csv('/kaggle/working/answersH.csv', index = False)\n",
        "x=pd.read_csv(\"/kaggle/working/answersH.csv\")\n",
        "x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.917017Z",
          "iopub.status.idle": "2025-06-18T07:28:06.917335Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.91717Z",
          "shell.execute_reply": "2025-06-18T07:28:06.917181Z"
        },
        "id": "JOS878QUujD4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#Doing it for Bengali"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.918319Z",
          "iopub.status.idle": "2025-06-18T07:28:06.918622Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.918476Z",
          "shell.execute_reply": "2025-06-18T07:28:06.91849Z"
        },
        "id": "9loIYofMujD4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/kaggle/input/trainnn/train_data1.json', 'r') as file:\n",
        "  # Replace this path with the dataset path in your local machine\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.921004Z",
          "iopub.status.idle": "2025-06-18T07:28:06.921272Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.92115Z",
          "shell.execute_reply": "2025-06-18T07:28:06.921161Z"
        },
        "id": "t4RzgSz4ujD9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Process JSON data\n",
        "source_sentences_train = []\n",
        "target_sentences_train = []\n",
        "\n",
        "source_sentences_val = []\n",
        "target_sentences_val = []\n",
        "\n",
        "id_train = []\n",
        "id_val = []"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.922798Z",
          "iopub.status.idle": "2025-06-18T07:28:06.923084Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.92294Z",
          "shell.execute_reply": "2025-06-18T07:28:06.922952Z"
        },
        "id": "MBrNQsdeujD9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for language_pair, language_data in data.items():\n",
        "    if(language_pair == \"English-Bengali\"):\n",
        "      print(f\"Language Pair: {language_pair}\")\n",
        "      for data_type, data_entries in language_data.items():\n",
        "          print(f\"  Data Type: {data_type}\")\n",
        "          for entry_id, entry_data in data_entries.items():\n",
        "              source = entry_data[\"source\"]\n",
        "              target = entry_data[\"target\"]\n",
        "              if (data_type == \"Validation\"):\n",
        "                source_sentences_val.append(source)\n",
        "                target_sentences_val.append(target)\n",
        "                id_val.append(entry_id)\n",
        "              else:\n",
        "                source_sentences_train.append(source)\n",
        "                target_sentences_train.append(target)\n",
        "                id_train.append(entry_id)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.92537Z",
          "iopub.status.idle": "2025-06-18T07:28:06.925674Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.925534Z",
          "shell.execute_reply": "2025-06-18T07:28:06.925549Z"
        },
        "id": "sKNdzNCIujD9"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/kaggle/input/validation/val_data1.json', 'r') as file: # Replace this path with the dataset path in your local machine\n",
        "    data = json.load(file)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.927056Z",
          "iopub.status.idle": "2025-06-18T07:28:06.930062Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.929896Z",
          "shell.execute_reply": "2025-06-18T07:28:06.92991Z"
        },
        "id": "PTALcWVDujD-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for language_pair, language_data in data.items():\n",
        "    if(language_pair == \"English-Bengali\"):\n",
        "      print(f\"Language Pair: {language_pair}\")\n",
        "      for data_type, data_entries in language_data.items():\n",
        "          print(f\"  Data Type: {data_type}\")\n",
        "          for entry_id, entry_data in data_entries.items():\n",
        "              source = entry_data[\"source\"]\n",
        "              #target = entry_data[\"target\"]\n",
        "              if (data_type == \"Validation\"):\n",
        "                source_sentences_val.append(source)\n",
        "                #target_sentences_val.append(target)\n",
        "                #id_val.append(entry_id)\n",
        "              #else:\n",
        "                #source_sentences_train.append(source)\n",
        "                #target_sentences_train.append(target)\n",
        "                #id_train.append(entry_id)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.931932Z",
          "iopub.status.idle": "2025-06-18T07:28:06.932272Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.932082Z",
          "shell.execute_reply": "2025-06-18T07:28:06.932095Z"
        },
        "id": "q1XwTmGHujD-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(source_sentences_train))\n",
        "print(len(target_sentences_train))\n",
        "\n",
        "print(len(source_sentences_val))\n",
        "print(len(target_sentences_val))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.933211Z",
          "iopub.status.idle": "2025-06-18T07:28:06.933543Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.933416Z",
          "shell.execute_reply": "2025-06-18T07:28:06.933429Z"
        },
        "id": "YXR-IdDsujD-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "x={'English':source_sentences_train,'Bengali':target_sentences_train}\n",
        "df=pd.DataFrame(x)\n",
        "df"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.934856Z",
          "iopub.status.idle": "2025-06-18T07:28:06.935345Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.935164Z",
          "shell.execute_reply": "2025-06-18T07:28:06.935179Z"
        },
        "id": "TPuVAQWjujD-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from collections import Counter\n",
        "\n",
        "target_sentences_train = [re.sub(r'[a-zA-Z]','',hi) for hi in target_sentences_train] #optional"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.936817Z",
          "iopub.status.idle": "2025-06-18T07:28:06.93709Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.936973Z",
          "shell.execute_reply": "2025-06-18T07:28:06.936983Z"
        },
        "id": "ooWdH84zujD-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "english_tokens = preprocess(source_sentences_train)\n",
        "english_test=preprocess(source_sentences_val)\n",
        "bengali_tokens = preprocess(target_sentences_train)\n",
        "bengali_test=preprocess(target_sentences_val)\n",
        "\n",
        "en_train=english_tokens\n",
        "en_test=english_test\n",
        "be_train=bengali_tokens\n",
        "be_test=bengali_test"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.938298Z",
          "iopub.status.idle": "2025-06-18T07:28:06.938772Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.938622Z",
          "shell.execute_reply": "2025-06-18T07:28:06.938637Z"
        },
        "id": "hhi8twk9ujD_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "en_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
        "be_index2word = [\"<PAD>\", \"<SOS>\", \"<EOS>\"]\n",
        "\n",
        "for ds in [en_train, en_test]:\n",
        "    for sent in ds:\n",
        "        for token in sent:\n",
        "            if token not in en_index2word:\n",
        "                en_index2word.append(token)\n",
        "\n",
        "for ds in [be_train, be_test]:\n",
        "    for sent in ds:\n",
        "        for token in sent:\n",
        "            if token not in be_index2word:\n",
        "                be_index2word.append(token)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.941002Z",
          "iopub.status.idle": "2025-06-18T07:28:06.941387Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.941167Z",
          "shell.execute_reply": "2025-06-18T07:28:06.941184Z"
        },
        "id": "-PaCR_8kujD_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "en_index2word"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.942924Z",
          "iopub.status.idle": "2025-06-18T07:28:06.943186Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.943068Z",
          "shell.execute_reply": "2025-06-18T07:28:06.943078Z"
        },
        "id": "V3tfc6IHujD_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.944422Z",
          "iopub.status.idle": "2025-06-18T07:28:06.944759Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.94457Z",
          "shell.execute_reply": "2025-06-18T07:28:06.944581Z"
        },
        "id": "0qUtbWN4ujD_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "en_word2index = {token: idx for idx, token in enumerate(en_index2word)}\n",
        "be_word2index = {token: idx for idx, token in enumerate(be_index2word)}\n",
        "\n",
        "len(en_word2index)\n",
        "\n",
        "en_lengths = sum([len(sent) for sent in en_train])/len(en_train)\n",
        "be_lengths = sum([len(sent) for sent in be_train])/len(be_train)\n",
        "\n",
        "seq_length = 25"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.946182Z",
          "iopub.status.idle": "2025-06-18T07:28:06.946601Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.946378Z",
          "shell.execute_reply": "2025-06-18T07:28:06.946394Z"
        },
        "id": "IRLVQT3PujD_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "en_train_encoded = [encode_and_pad(en_word2index, sent, seq_length) for sent in en_train]\n",
        "en_test_encoded = [encode_and_pad(en_word2index, sent, seq_length) for sent in en_test]\n",
        "be_train_encoded = [encode_and_pad(be_word2index, sent, seq_length) for sent in be_train]\n",
        "be_test_encoded = [encode_and_pad(be_word2index, sent, seq_length) for sent in be_test]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.947667Z",
          "iopub.status.idle": "2025-06-18T07:28:06.948018Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.947836Z",
          "shell.execute_reply": "2025-06-18T07:28:06.947852Z"
        },
        "id": "qbnc1nHlujD_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "en_train_encoded[1]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.94927Z",
          "iopub.status.idle": "2025-06-18T07:28:06.949825Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.949625Z",
          "shell.execute_reply": "2025-06-18T07:28:06.949642Z"
        },
        "id": "NORRz7NAujEA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "\n",
        "train_x = np.array(en_train_encoded)\n",
        "train_y = np.array(be_train_encoded)\n",
        "test_x = np.array(en_test_encoded)\n",
        "test_y = np.array(be_test_encoded)\n",
        "\n",
        "train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "test_ds = TensorDataset(torch.from_numpy(test_x))\n",
        "\n",
        "\n",
        "train_dl = DataLoader(train_ds, shuffle=True, batch_size=batch_size, drop_last=True)\n",
        "#test_dl = DataLoader(test_ds, shuffle=True, batch_size=batch_size, drop_last=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.950768Z",
          "iopub.status.idle": "2025-06-18T07:28:06.951136Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.950938Z",
          "shell.execute_reply": "2025-06-18T07:28:06.950953Z"
        },
        "id": "J-cTxesxujEA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_x[1]\n",
        "train_ds[1]\n",
        "\n",
        "hidden_size = 128\n",
        "seq_length = 25"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.952034Z",
          "iopub.status.idle": "2025-06-18T07:28:06.952412Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.952203Z",
          "shell.execute_reply": "2025-06-18T07:28:06.952218Z"
        },
        "id": "bd2uA4ApujEA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = EncoderRNN(len(en_index2word), hidden_size).to(device)\n",
        "decoder = DecoderRNN(hidden_size, len(be_index2word)).to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.953493Z",
          "iopub.status.idle": "2025-06-18T07:28:06.95385Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.953669Z",
          "shell.execute_reply": "2025-06-18T07:28:06.953685Z"
        },
        "id": "9A6gHwKbujEB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "enc_optimizer = torch.optim.Adam(encoder.parameters(), lr = 3e-3)\n",
        "dec_optimizer = torch.optim.Adam(decoder.parameters(), lr = 3e-3)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.955244Z",
          "iopub.status.idle": "2025-06-18T07:28:06.95554Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.955421Z",
          "shell.execute_reply": "2025-06-18T07:28:06.955432Z"
        },
        "id": "L99dG-qOujEB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "input_length = target_length = seq_length\n",
        "\n",
        "SOS = en_word2index[\"<SOS>\"]\n",
        "EOS = en_word2index[\"<EOS>\"]\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for idx, batch in enumerate(train_dl):\n",
        "\n",
        "        # Creating initial hidden states for the encoder\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        # Sending to device\n",
        "        encoder_hidden = encoder_hidden.to(device)\n",
        "\n",
        "        # Assigning the input and sending to device\n",
        "        input_tensor = batch[0].to(device)\n",
        "\n",
        "        # Assigning the output and sending to device\n",
        "        target_tensor = batch[1].to(device)\n",
        "\n",
        "\n",
        "        # Clearing gradients\n",
        "        enc_optimizer.zero_grad()\n",
        "        dec_optimizer.zero_grad()\n",
        "\n",
        "        # Enabling gradient calculation\n",
        "        with torch.set_grad_enabled(True):\n",
        "\n",
        "            # Feeding batch into encoder\n",
        "            encoder_output, (hidden, cell) = encoder(input_tensor, encoder_hidden)\n",
        "            encoder_hidden = (hidden, cell)\n",
        "\n",
        "            # This is a placeholder tensor for decoder outputs. We send it to device as well\n",
        "            dec_result = torch.zeros(target_length, batch_size, len(be_index2word)).to(device)\n",
        "\n",
        "            # Creating a batch of SOS tokens which will all be fed to the decoder\n",
        "            decoder_input = target_tensor[:, 0].unsqueeze(1).to(device)\n",
        "\n",
        "            # Creating initial hidden states of the decoder by copying encoder hidden states\n",
        "            decoder_hidden = (\n",
        "                hidden.mean(dim=0, keepdim=True),\n",
        "                cell.mean(dim=0, keepdim=True)\n",
        "            )\n",
        "\n",
        "            # For each time-step in decoding:\n",
        "            for i in range(1, target_length):\n",
        "\n",
        "                # Feed input and previous hidden states\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "\n",
        "                # Finding the best scoring word\n",
        "                best = decoder_output.argmax(1)\n",
        "\n",
        "                # Assigning next input as current best word\n",
        "                decoder_input = best.unsqueeze(1)\n",
        "\n",
        "                # Creating an entry in the placeholder output tensor\n",
        "                dec_result[i] = decoder_output\n",
        "\n",
        "\n",
        "            # Creating scores and targets for loss calculation\n",
        "            scores = dec_result.transpose(1, 0)[1:].reshape(-1, dec_result.shape[2])\n",
        "            targets = target_tensor[1:].reshape(-1)\n",
        "\n",
        "            # Calculating loss\n",
        "            loss = criterion(scores, targets)\n",
        "\n",
        "            # Performing backprop and clipping excess gradients\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "            torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1)\n",
        "\n",
        "            enc_optimizer.step()\n",
        "            dec_optimizer.step()\n",
        "\n",
        "            # Keeping track of loss\n",
        "            losses.append(loss.item())\n",
        "            if idx % 100 == 0:\n",
        "                print(idx, sum(losses)/len(losses))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.956771Z",
          "iopub.status.idle": "2025-06-18T07:28:06.95702Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.956902Z",
          "shell.execute_reply": "2025-06-18T07:28:06.956912Z"
        },
        "id": "PSdQVkL3ujEB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(losses)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.959075Z",
          "iopub.status.idle": "2025-06-18T07:28:06.95942Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.959253Z",
          "shell.execute_reply": "2025-06-18T07:28:06.959267Z"
        },
        "id": "20x561TLujEB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "val_ids = [ i for i,_ in data[\"English-Bengali\"][\"Validation\"].items()]\n",
        "\n",
        "val_outs = []\n",
        "for i in tqdm(range(len(test_ds))):\n",
        "    # Fix 1: Initialize encoder hidden state with correct bidirectional dimensions\n",
        "    encoder_hidden = torch.zeros(2, 1, hidden_size).to(device)  # (2 directions, batch_size=1, hidden_size)\n",
        "\n",
        "    input_tensor = test_ds[i][0].unsqueeze(dim=0).to(device)\n",
        "    result = []\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        encoder_output, (hidden, cell) = encoder(input_tensor, encoder_hidden)\n",
        "        encoder_hidden = (hidden, cell)\n",
        "        decoder_hidden = hidden.mean(dim=0).unsqueeze(0)  # (1 layer, batch_size=1, hidden_size)\n",
        "        decoder_input = torch.tensor([SOS]).unsqueeze(dim=1).to(device)  # (batch=1, seq_len=1)\n",
        "\n",
        "        for di in range(1, target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            best = decoder_output.argmax(1)\n",
        "            result.append(be_index2word[best.to('cpu').item()])\n",
        "\n",
        "            if best.item() == EOS:\n",
        "                break\n",
        "\n",
        "            # Maintain consistent dimension for next input\n",
        "            decoder_input = best.unsqueeze(1)  # (batch=1, seq_len=1)\n",
        "\n",
        "    result = [i for i in result if i not in ['<EOS>', '<PAD>', '<SOS>']]\n",
        "    val_outs.append(\" \".join(result))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.959997Z",
          "iopub.status.idle": "2025-06-18T07:28:06.960371Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.960161Z",
          "shell.execute_reply": "2025-06-18T07:28:06.960177Z"
        },
        "id": "HmZZiLpzujEC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df0 = pd.DataFrame()\n",
        "df0[\"ID\"] = val_ids\n",
        "df0[\"Translation\"] = val_outs"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.961108Z",
          "iopub.status.idle": "2025-06-18T07:28:06.961417Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.961243Z",
          "shell.execute_reply": "2025-06-18T07:28:06.961257Z"
        },
        "id": "tmOAldZUujEC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df0.to_csv('answersB.csv', index = False)\n",
        "x=pd.read_csv(\"/kaggle/working/answersB.csv\")\n",
        "x"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.962535Z",
          "iopub.status.idle": "2025-06-18T07:28:06.962782Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.962668Z",
          "shell.execute_reply": "2025-06-18T07:28:06.962678Z"
        },
        "id": "7iZEHvkxujEC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.read_csv(\"/kaggle/working/answersB.csv\") # Bengali\n",
        "df2= pd.read_csv(\"/kaggle/working/answersH.csv\")  # Hindi"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.964106Z",
          "iopub.status.idle": "2025-06-18T07:28:06.964448Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.964306Z",
          "shell.execute_reply": "2025-06-18T07:28:06.964321Z"
        },
        "id": "laIVxStSujEC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.concat([df1, df2]) #Concat\n",
        "df3.to_csv('answersBH.csv', index = False)\n",
        "filtered_data = pd.read_csv(\"/kaggle/working/answersBH.csv\")\n",
        "\n",
        "answer = \"/kaggle/working/answer.csv\"\n",
        "with open(answer, \"w\") as f:\n",
        "  f.writelines(\"ID\\tTranslation\\n\")\n",
        "  for i in range(filtered_data.shape[0]):\n",
        "    f.writelines(f'{filtered_data[\"ID\"][i]}\\t\"{filtered_data[\"Translation\"][i]}\"\\n')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-06-18T07:28:06.965428Z",
          "iopub.status.idle": "2025-06-18T07:28:06.965665Z",
          "shell.execute_reply.started": "2025-06-18T07:28:06.965544Z",
          "shell.execute_reply": "2025-06-18T07:28:06.965561Z"
        },
        "id": "c_tNGVojujEC"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}